{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5bbf5bf",
   "metadata": {},
   "source": [
    "## Attempting data analysis for P1\n",
    "TODO:\n",
    "1. merge relevant datasets\n",
    "2. extract all gestures with mappings to text descriptions\n",
    "3. preliminary attemps to classify gesture\n",
    "4. generate visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e560781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbf78b",
   "metadata": {},
   "source": [
    "### 1. merge relevant datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7393bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "all_flat = sorted(glob.glob(os.path.join(cwd, \"data/P1*FLAT*csv\")))\n",
    "all_pillow = sorted(glob.glob(os.path.join(cwd, \"data/P1*PILLOW*.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51b49393",
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = {\n",
    "    109: \"massage\",\n",
    "    114: \"rub\",\n",
    "    100: \"drag\",\n",
    "    115: \"slide\",\n",
    "    112: \"poke\",\n",
    "    97: \"pat\",\n",
    "    101: \"press\",\n",
    "    116: \"tap\",\n",
    "    110: \"pinch\",\n",
    "    107: \"knead\",\n",
    "    119: \"twist\",\n",
    "    111: \"none\",\n",
    "    99: \"constant\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6441e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_idx = list(filter(lambda n:n%5==3, range(1, 181)))\n",
    "shear_up_idx = list(filter(lambda n:n%5==1, range(1, 181)))\n",
    "shear_down_idx = list(filter(lambda n:n%5==0, range(1, 181)))\n",
    "shear_left_idx = list(filter(lambda n:n%5==2, range(1, 181)))\n",
    "shear_right_idx = list(filter(lambda n:n%5==4, range(1, 181)))\n",
    "\n",
    "def transform_raw_data(df):\n",
    "    def find_shear_x(l, r, l_avg, r_avg):\n",
    "        return (l*r_avg - r*l_avg)/(l_avg + r_avg)\n",
    "\n",
    "    def find_shear_y(u, d, u_avg, d_avg):\n",
    "        return (u*d_avg - d*u_avg)/(u_avg + d_avg)\n",
    "    \n",
    "    avg = df.iloc[0, 1:181].to_numpy()\n",
    "    time_stamps = df.pop(df.columns[0])\n",
    "    labels = df.pop(df.columns[181]).map(lambda x: gestures.get(x))\n",
    "    \n",
    "    pressure = df[pressure_idx].to_numpy()\n",
    "    shear_up = df[shear_up_idx].to_numpy()\n",
    "    shear_down = df[shear_down_idx].to_numpy()\n",
    "    shear_left = df[shear_left_idx].to_numpy()\n",
    "    shear_right = df[shear_right_idx].to_numpy()\n",
    "    \n",
    "    shear_y = np.zeros(shear_up.shape)\n",
    "    shear_x = np.zeros(shear_up.shape)\n",
    "\n",
    "    for i in range(0, shear_up.shape[0]):\n",
    "        for j in range(0, 36):\n",
    "            shear_y[i][j] = find_shear_y(shear_up[i][j], shear_down[i][j], avg[5*j], avg[5*j+4])\n",
    "            shear_x[i][j] = find_shear_x(shear_left[i][j], shear_right[i][j], avg[5*j+1], avg[5*j+3])\n",
    "            \n",
    "    shear_y_3d = shear_y.reshape(6, 6, shear_y.shape[0])\n",
    "    shear_x_3d = shear_x.reshape(6, 6, shear_y.shape[0])\n",
    "    pressure_3d = pressure.reshape(6, 6, shear_y.shape[0])\n",
    "    \n",
    "    shear_y_3d[np.where(np.isnan(shear_y_3d))] = 0\n",
    "    shear_x_3d[np.where(np.isnan(shear_x_3d))] = 0\n",
    "    pressure_3d[np.where(np.isnan(pressure_3d))] = 0\n",
    "\n",
    "    return (shear_x_3d, shear_y_3d, pressure_3d, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91c925a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(all_flat[\u001b[38;5;241m0\u001b[39m], header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, skiprows\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m shear_x_3d, shear_y_3d, pressure_3d, labels \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(shear_x_3d)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(shear_y_3d)\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mtransform_raw_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m avg \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m181\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     15\u001b[0m time_stamps \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpop(df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m181\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgestures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m pressure \u001b[38;5;241m=\u001b[39m df[pressure_idx]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     19\u001b[0m shear_up \u001b[38;5;241m=\u001b[39m df[shear_up_idx]\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4237\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4163\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4235\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4239\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4240\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/base.py:880\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mmap_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mtransform_raw_data.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m avg \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m181\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     15\u001b[0m time_stamps \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpop(df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m labels \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpop(df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m181\u001b[39m])\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mgestures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     18\u001b[0m pressure \u001b[38;5;241m=\u001b[39m df[pressure_idx]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     19\u001b[0m shear_up \u001b[38;5;241m=\u001b[39m df[shear_up_idx]\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(all_flat[0], header=None, skiprows=[0])\n",
    "shear_x_3d, shear_y_3d, pressure_3d, labels = transform_raw_data(df)\n",
    "print(shear_x_3d)\n",
    "print(shear_y_3d)\n",
    "print(pressure_3d)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de68684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/suzettesun/ubc/spin/shear-sense/data/P1_Mar15th2023_1_FLAT 17_26_17.csv',\n",
       " '/Users/suzettesun/ubc/spin/shear-sense/data/P1_Mar15th2023_1_FLAT 18_07_22.csv']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5342fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81fe2407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd23ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2af550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa23c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42f1b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7eae775-668a-49d5-8e02-e2e6c86d3a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1162d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = df.iloc[:,181].to_numpy().reshape(1,1,df.shape[0])\n",
    "outcome = outcome.flatten()\n",
    "outcome[np.where(np.isnan(outcome))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f72fcd4-2065-4840-a6f0-1459ee234973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max': 1374.0, 'min': 0.0},\n",
       " {'max': 0.6708566953083422, 'min': -0.12461090070775589},\n",
       " {'max': 1424221.487843917, 'min': -1.0602960803596515}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxvals = [{'max': np.max(arr), 'min': np.min(arr)} for arr in [pressure_3d, shear_x_3d, shear_y_3d]]\n",
    "minmaxvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4021b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "267a9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [np.dstack((pressure_3d[:,:,i], shear_x_3d[:,:,i], shear_y_3d[:, :, i])) for i in range(shear_y.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec0ca02-456c-41ac-b39b-89e6a81c03aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 6, 3), 1231)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b3d610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.22637000e+03, -6.94541817e-02, -1.06029608e+00],\n",
       "        [ 1.18600000e+03, -1.50492236e-02, -3.48814888e-02],\n",
       "        [ 1.17900000e+03, -1.01707868e-02, -8.19108746e-03],\n",
       "        [ 1.22300000e+03, -4.28184720e-02,  9.93936079e-03],\n",
       "        [ 1.29500000e+03, -7.70004699e-02, -1.84361549e-02],\n",
       "        [ 1.34000000e+03, -2.86718080e-02, -4.96846407e-02]],\n",
       "\n",
       "       [[ 1.24000000e+03, -9.18207017e-02,  1.88596678e-01],\n",
       "        [ 1.17400000e+03,  2.20897404e-02, -2.57996164e-02],\n",
       "        [ 1.23000000e+03, -4.48243257e-02,  3.79204438e-02],\n",
       "        [ 1.19100000e+03,  2.73607921e-02, -8.36922189e-02],\n",
       "        [ 1.31000000e+03, -5.26963630e-02, -2.68620160e-02],\n",
       "        [ 1.30400000e+03,  4.25106302e-02,  3.35230824e-02]],\n",
       "\n",
       "       [[ 1.20500000e+03, -7.78837772e-02,  2.32135185e-01],\n",
       "        [ 1.16900000e+03,  1.12862337e-02, -4.10221267e-02],\n",
       "        [ 1.19500000e+03,  1.09649815e-02, -6.49201141e-02],\n",
       "        [ 1.23800000e+03, -2.50718528e-02, -1.57822499e-02],\n",
       "        [ 1.30300000e+03, -4.23358225e-02,  2.17083958e-04],\n",
       "        [ 1.30900000e+03,  1.80816085e-02,  6.63011344e-02]],\n",
       "\n",
       "       [[ 1.22800000e+03, -5.92668185e-02,  1.88843550e-01],\n",
       "        [ 1.17300000e+03, -3.68759650e-02,  1.18760701e-02],\n",
       "        [ 1.23400000e+03, -3.75113733e-02, -2.73401853e-02],\n",
       "        [ 1.23100000e+03, -4.28880673e-02,  6.58856261e-02],\n",
       "        [ 1.32100000e+03, -4.81852662e-02, -7.43590529e-03],\n",
       "        [ 1.35100000e+03, -2.88432908e-02,  6.26900923e-02]],\n",
       "\n",
       "       [[ 1.21700000e+03, -7.10561298e-02,  1.62129118e-01],\n",
       "        [ 1.20900000e+03, -1.45755031e-02, -3.54685865e-02],\n",
       "        [ 1.24200000e+03, -4.43410748e-02, -2.37678169e-03],\n",
       "        [ 1.25300000e+03, -3.40276594e-02,  2.31813819e-02],\n",
       "        [ 1.31600000e+03, -5.93888555e-02,  1.20196297e-02],\n",
       "        [ 1.27200000e+03,  7.10171615e-02,  2.18433071e-03]],\n",
       "\n",
       "       [[ 1.24200000e+03, -8.73718279e-02,  2.20933418e-01],\n",
       "        [ 1.17900000e+03,  6.67418674e-01, -4.24891604e-01],\n",
       "        [ 1.21500000e+03, -9.75002162e-02,  5.18459019e-02],\n",
       "        [ 1.24900000e+03, -1.21378457e-01,  1.36162261e-01],\n",
       "        [ 1.31000000e+03, -5.24931039e-02,  4.46371164e-02],\n",
       "        [ 1.34200000e+03, -1.11316344e-02,  2.78765687e-02]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3678188d-0ae3-446b-88ad-34d0039d7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    arr = arr.astype('float')\n",
    "    for i in range(3):\n",
    "        minval = minmaxvals[i]['min']\n",
    "        maxval = minmaxvals[i]['max']\n",
    "        if minval != maxval:\n",
    "            arr[..., i] -= minval\n",
    "            arr[..., i] *= (255.0 / (maxval - minval))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b97532f3-7533-42b6-80e1-5ade4ef9a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = im.fromarray(normalize(data[0]).astype('uint8'),'RGB')\n",
    "\n",
    "basewidth = 300\n",
    "wpercent = (basewidth / float(img.size[0]))\n",
    "hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "img = img.resize((basewidth, hsize), im.Resampling.LANCZOS)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9109c6d8-372b-48e6-b0be-655dd4af04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3a34bd1-f14f-4bc0-b8ba-caba2dfe4eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (300, 300) to (304, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (300, 300) to (304, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (300, 300) to (304, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (300, 300) to (304, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "writer = imageio.get_writer('all_channels.mp4', fps=30)\n",
    "writer_shearx = imageio.get_writer('shear_x.mp4', fps=30)\n",
    "writer_sheary = imageio.get_writer('shear_y.mp4', fps=30)\n",
    "writer_pressure = imageio.get_writer('pressure.mp4', fps=30)\n",
    "\n",
    "\n",
    "for instance in data:\n",
    "    img = im.fromarray(normalize(instance).astype('uint8'),'RGB')\n",
    "    img = img.resize((basewidth, hsize), im.Resampling.LANCZOS)\n",
    "    pressure, shear_x, shear_y = img.split()\n",
    "    \n",
    "    writer.append_data(np.array(img))\n",
    "    writer_pressure.append_data(np.array(pressure))\n",
    "    writer_shearx.append_data(np.array(shear_x))\n",
    "    writer_sheary.append_data(np.array(shear_y))\n",
    "\n",
    "writer.close()\n",
    "writer_pressure.close()\n",
    "writer_shearx.close()\n",
    "writer_sheary.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cfcc2c-a648-42bd-bfa6-220a07ca2a1e",
   "metadata": {},
   "source": [
    "# 3D CNN for video classification\n",
    "\n",
    "Follow tutorial: https://www.tensorflow.org/tutorials/video/video_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5e6a9-d4ea-4ce8-b3d0-d6efc0882267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb8ef8-663f-46cb-ae35-6864790182a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_per_class(zip_url):\n",
    "    \"\"\"\n",
    "    List the files in each class of the dataset given the zip URL.\n",
    "\n",
    "    Args:\n",
    "      zip_url: URL from which the files can be unzipped. \n",
    "\n",
    "    Return:\n",
    "      files: List of files in each of the classes.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    with rz.RemoteZip(URL) as zip:\n",
    "        for zip_info in zip.infolist():\n",
    "            files.append(zip_info.filename)\n",
    "    return files\n",
    "\n",
    "def get_class(fname):\n",
    "  \"\"\"\n",
    "    Retrieve the name of the class given a filename.\n",
    "\n",
    "    Args:\n",
    "      fname: Name of the file in the UCF101 dataset.\n",
    "\n",
    "    Return:\n",
    "      Class that the file belongs to.\n",
    "  \"\"\"\n",
    "  return fname.split('_')[-3]\n",
    "\n",
    "def get_files_per_class(files):\n",
    "  \"\"\"\n",
    "    Retrieve the files that belong to each class. \n",
    "\n",
    "    Args:\n",
    "      files: List of files in the dataset.\n",
    "\n",
    "    Return:\n",
    "      Dictionary of class names (key) and files (values).\n",
    "  \"\"\"\n",
    "    files_for_class = collections.defaultdict(list)\n",
    "    for fname in files:\n",
    "        class_name = get_class(fname)\n",
    "        files_for_class[class_name].append(fname)\n",
    "    return files_for_class\n",
    "\n",
    "def download_from_zip(zip_url, to_dir, file_names):\n",
    "    \"\"\"\n",
    "    Download the contents of the zip file from the zip URL.\n",
    "\n",
    "    Args:\n",
    "      zip_url: Zip URL containing data.\n",
    "      to_dir: Directory to download data to.\n",
    "      file_names: Names of files to download.\n",
    "    \"\"\"\n",
    "    with rz.RemoteZip(zip_url) as zip:\n",
    "        for fn in tqdm.tqdm(file_names):\n",
    "            class_name = get_class(fn)\n",
    "            zip.extract(fn, str(to_dir / class_name))\n",
    "            unzipped_file = to_dir / class_name / fn\n",
    "\n",
    "            fn = pathlib.Path(fn).parts[-1]\n",
    "            output_file = to_dir / class_name / fn\n",
    "            unzipped_file.rename(output_file,)\n",
    "\n",
    "def split_class_lists(files_for_class, count):\n",
    "    \"\"\"\n",
    "    Returns the list of files belonging to a subset of data as well as the remainder of\n",
    "    files that need to be downloaded.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Files belonging to a particular class of data.\n",
    "      count: Number of files to download.\n",
    "\n",
    "    Return:\n",
    "      split_files: Files belonging to the subset of data.\n",
    "      remainder: Dictionary of the remainder of files that need to be downloaded.\n",
    "    \"\"\"\n",
    "    split_files = []\n",
    "    remainder = {}\n",
    "    for cls in files_for_class:\n",
    "        split_files.extend(files_for_class[cls][:count])\n",
    "        remainder[cls] = files_for_class[cls][count:]\n",
    "    return split_files, remainder\n",
    "\n",
    "def download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n",
    "    \"\"\"\n",
    "    Download a subset of the UFC101 dataset and split them into various parts, such as\n",
    "    training, validation, and test. \n",
    "\n",
    "    Args:\n",
    "      zip_url: Zip URL containing data.\n",
    "      num_classes: Number of labels.\n",
    "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data \n",
    "              (value is number of files per split).\n",
    "      download_dir: Directory to download data to.\n",
    "\n",
    "    Return:\n",
    "      dir: Posix path of the resulting directories containing the splits of data.\n",
    "    \"\"\"\n",
    "    files = list_files_per_class(zip_url)\n",
    "    for f in files:\n",
    "        tokens = f.split('/')\n",
    "        if len(tokens) <= 2:\n",
    "            files.remove(f) # Remove that item from the list if it does not have a filename\n",
    "\n",
    "    files_for_class = get_files_per_class(files)\n",
    "\n",
    "    classes = list(files_for_class.keys())[:num_classes]\n",
    "\n",
    "    for cls in classes:\n",
    "        new_files_for_class = files_for_class[cls]\n",
    "        random.shuffle(new_files_for_class)\n",
    "        files_for_class[cls] = new_files_for_class\n",
    "\n",
    "    # Only use the number of classes you want in the dictionary\n",
    "    files_for_class = {x: files_for_class[x] for x in list(files_for_class)[:num_classes]}\n",
    "\n",
    "    dirs = {}\n",
    "    for split_name, split_count in splits.items():\n",
    "        print(split_name, \":\")\n",
    "        split_dir = download_dir / split_name\n",
    "        split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
    "        download_from_zip(zip_url, split_dir, split_files)\n",
    "        dirs[split_name] = split_dir\n",
    "        \n",
    "    return dirs\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "    \"\"\"\n",
    "    Pad and resize an image from a video.\n",
    "\n",
    "    Args:\n",
    "      frame: Image that needs to resized and padded. \n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      Formatted frame with padding of specified output size.\n",
    "    \"\"\"\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    return frame\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n",
    "    \"\"\"\n",
    "    Creates frames from each video file present for each category.\n",
    "\n",
    "    Args:\n",
    "      video_path: File path to the video.\n",
    "      n_frames: Number of frames to be created per video file.\n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "    \"\"\"\n",
    "    # Read each video frame by frame\n",
    "    result = []\n",
    "    src = cv2.VideoCapture(str(video_path))  \n",
    "\n",
    "    video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "    if need_length > video_length:\n",
    "        start = 0\n",
    "    else:\n",
    "        max_start = video_length - need_length\n",
    "        start = random.randint(0, max_start + 1)\n",
    "\n",
    "    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "    # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "    ret, frame = src.read()\n",
    "    result.append(format_frames(frame, output_size))\n",
    "\n",
    "    for _ in range(n_frames - 1):\n",
    "        for _ in range(frame_step):\n",
    "            ret, frame = src.read()\n",
    "        if ret:\n",
    "            frame = format_frames(frame, output_size)\n",
    "            result.append(frame)\n",
    "        else:\n",
    "            result.append(np.zeros_like(result[0]))\n",
    "    src.release()\n",
    "    result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "    return result\n",
    "\n",
    "class FrameGenerator:\n",
    "    def __init__(self, path, n_frames, training = False):\n",
    "    \"\"\" Returns a set of frames with their associated label. \n",
    "\n",
    "      Args:\n",
    "        path: Video file paths.\n",
    "        n_frames: Number of frames. \n",
    "        training: Boolean to determine if training dataset is being created.\n",
    "    \"\"\"\n",
    "        self.path = path\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "        self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "    def get_files_and_class_names(self):\n",
    "        video_paths = list(self.path.glob('*/*.avi'))\n",
    "        classes = [p.parent.name for p in video_paths] \n",
    "        return video_paths, classes\n",
    "\n",
    "    def __call__(self):\n",
    "        video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "        pairs = list(zip(video_paths, classes))\n",
    "\n",
    "        if self.training:\n",
    "            random.shuffle(pairs)\n",
    "\n",
    "        for path, name in pairs:\n",
    "            video_frames = frames_from_video_file(path, self.n_frames) \n",
    "            label = self.class_ids_for_name[name] # Encode labels\n",
    "            yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e0e71-fc56-444a-bb17-c31890fe81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'\n",
    "download_dir = pathlib.Path('./UCF101_subset/')\n",
    "subset_paths = download_ufc_101_subset(URL, \n",
    "                        num_classes = 10, \n",
    "                        splits = {\"train\": 30, \"val\": 10, \"test\": 10},\n",
    "                        download_dir = download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14426a9-b38e-4e3c-9382-6b91505072b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 10\n",
    "batch_size = 8\n",
    "\n",
    "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], n_frames, training=True),\n",
    "                                          output_signature = output_signature)\n",
    "\n",
    "\n",
    "# Batch the data\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], n_frames),\n",
    "                                        output_signature = output_signature)\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], n_frames),\n",
    "                                         output_signature = output_signature)\n",
    "\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d83ed3-fd17-46b5-9b59-3ce17d917a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions of one frame in the set of frames created\n",
    "HEIGHT = 224\n",
    "WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52791fcf-0b46-449b-b88f-29c51ab5a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "    \"\"\"\n",
    "      A sequence of convolutional layers that first apply the convolution operation over the\n",
    "      spatial dimensions, and then the temporal dimension. \n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.seq = keras.Sequential([  \n",
    "        # Spatial decomposition\n",
    "        layers.Conv3D(filters=filters,\n",
    "                      kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
    "                      padding=padding),\n",
    "        # Temporal decomposition\n",
    "        layers.Conv3D(filters=filters, \n",
    "                      kernel_size=(kernel_size[0], 1, 1),\n",
    "                      padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729143e-32b3-4ba3-80ed-8d3d98eac3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualMain(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Residual block of the model with convolution, layer normalization, and the\n",
    "    activation function, ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, \n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6018a1a-eccc-4501-a607-ea0aafdf7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Project(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Project certain dimensions of the tensor as the data is passed through different \n",
    "    sized filters and downsampled. \n",
    "    \"\"\"\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ba619-2602-4636-8dfd-a0a3113ede7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_residual_block(input, filters, kernel_size):\n",
    "    \"\"\"\n",
    "    Add residual blocks to the model. If the last dimensions of the input data\n",
    "    and filter size does not match, project it such that last dimension matches.\n",
    "    \"\"\"\n",
    "    out = ResidualMain(filters, \n",
    "                     kernel_size)(input)\n",
    "\n",
    "    res = input\n",
    "    # Using the Keras functional APIs, project the last dimension of the tensor to\n",
    "    # match the new filter size\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "\n",
    "    return layers.add([res, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701bb3b-9412-435d-8f5c-91334d7c8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "    \"\"\"\n",
    "      Use the einops library to resize the tensor.  \n",
    "\n",
    "      Args:\n",
    "        video: Tensor representation of the video, in the form of a set of frames.\n",
    "\n",
    "      Return:\n",
    "        A downsampled size of the video according to the new height and width it should be resized to.\n",
    "    \"\"\"\n",
    "        # b stands for batch size, t stands for time, h stands for height, \n",
    "        # w stands for width, and c stands for the number of channels.\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(\n",
    "            images, '(b t) h w c -> b t h w c',\n",
    "            t = old_shape['t'])\n",
    "        return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4759f-a53d-450c-8501-bc562bb47e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, 10, HEIGHT, WIDTH, 3)\n",
    "input = layers.Input(shape=(input_shape[1:]))\n",
    "x = input\n",
    "\n",
    "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n",
    "\n",
    "# Block 1\n",
    "x = add_residual_block(x, 16, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n",
    "\n",
    "# Block 2\n",
    "x = add_residual_block(x, 32, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n",
    "\n",
    "# Block 3\n",
    "x = add_residual_block(x, 64, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n",
    "\n",
    "# Block 4\n",
    "x = add_residual_block(x, 128, (3, 3, 3))\n",
    "\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(10)(x)\n",
    "\n",
    "model = keras.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece66290-1c35-4279-8aa7-7412609a1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, label = next(iter(train_ds))\n",
    "model.build(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cc492-7df1-44e9-a1e4-79ef4c9e5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model\n",
    "keras.utils.plot_model(model, expand_nested=True, dpi=60, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19875585-4c15-4947-a83b-c47a2910282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001), \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adce6df-63c3-4311-8731-837c65a81ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = train_ds,\n",
    "                    epochs = 50, \n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb03e4f-7cca-4eda-a30e-5c15a59747af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Plotting training and validation learning curves.\n",
    "\n",
    "    Args:\n",
    "      history: model history with all the metric measures\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    # Plot loss\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.plot(history.history['loss'], label = 'train')\n",
    "    ax1.plot(history.history['val_loss'], label = 'test')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    # Determine upper bound of y-axis\n",
    "    max_loss = max(history.history['loss'] + history.history['val_loss'])\n",
    "\n",
    "    ax1.set_ylim([0, np.ceil(max_loss)])\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation']) \n",
    "\n",
    "    # Plot accuracy\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.plot(history.history['accuracy'],  label = 'train')\n",
    "    ax2.plot(history.history['val_accuracy'], label = 'test')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f39c6-bf0a-4495-a5a3-3d7c92fa7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac7c23-064f-4fc7-bf44-5053752b0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(dataset): \n",
    "    \"\"\"\n",
    "    Create a list of actual ground truth values and the predictions from the model.\n",
    "\n",
    "    Args:\n",
    "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
    "\n",
    "    Return:\n",
    "      Ground truth and predicted values for a particular dataset.\n",
    "    \"\"\"\n",
    "    actual = [labels for _, labels in dataset.unbatch()]\n",
    "    predicted = model.predict(dataset)\n",
    "\n",
    "    actual = tf.stack(actual, axis=0)\n",
    "    predicted = tf.concat(predicted, axis=0)\n",
    "    predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "    return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e1251-2615-4328-8cb0-228ce3c6406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = FrameGenerator(subset_paths['train'], n_frames, training=True)\n",
    "labels = list(fg.class_ids_for_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbef896-6f59-42d0-8758-aeb1342e11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted = get_actual_predicted_labels(train_ds)\n",
    "plot_confusion_matrix(actual, predicted, labels, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c798597-1612-4bd1-a4c8-99e4f72d890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted = get_actual_predicted_labels(test_ds)\n",
    "plot_confusion_matrix(actual, predicted, labels, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9606a-a1a7-4850-ab04-3f5abc8d7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(y_actual, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Calculate the precision and recall of a classification model using the ground truth and\n",
    "    predicted values. \n",
    "\n",
    "    Args:\n",
    "      y_actual: Ground truth labels.\n",
    "      y_pred: Predicted labels.\n",
    "      labels: List of classification labels.\n",
    "\n",
    "    Return:\n",
    "      Precision and recall measures.\n",
    "    \"\"\"\n",
    "    cm = tf.math.confusion_matrix(y_actual, y_pred)\n",
    "    tp = np.diag(cm) # Diagonal represents true positives\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    for i in range(len(labels)):\n",
    "    col = cm[:, i]\n",
    "    fp = np.sum(col) - tp[i] # Sum of column minus true positive is false negative\n",
    "\n",
    "    row = cm[i, :]\n",
    "    fn = np.sum(row) - tp[i] # Sum of row minus true positive, is false negative\n",
    "\n",
    "    precision[labels[i]] = tp[i] / (tp[i] + fp) # Precision \n",
    "\n",
    "    recall[labels[i]] = tp[i] / (tp[i] + fn) # Recall\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff1486-c040-4092-91ea-163f23f4b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = calculate_classification_metrics(actual, predicted, labels) # Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ece662-23e6-44a5-9f87-f9dd7d61ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33bbee-517b-4bb0-95f3-937add149f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
